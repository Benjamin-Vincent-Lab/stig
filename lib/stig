#! /usr/bin/python


# STIG - Generate synthetic T-cell receptor reads in DNA and RNA
#
# Copyright (C) 2018 The University of North Carolina at Chapel Hill
# See LICENSE.txt

import sys
import re
import random
import argparse
from string import maketrans
from itertools import ifilter
from itertools import ifilterfalse
import logging
import math
import cPickle

import stigtools


# Configure our logging
log = logging.getLogger('main')
log.setLevel(logging.DEBUG)

# Stream handler to log warning and higher messages
sh = logging.StreamHandler()
sh.setFormatter(logging.Formatter(fmt='%(asctime)s.%(msecs)03d [%(levelname)s] %(name)s %(message)s',
                                  datefmt='%Y%m%d%H%M%S'))
log.addHandler(sh);

# Seed our internal random number generator
random.seed()


parser = argparse.ArgumentParser(description = "Generate synthetic TCR read data",
																 epilog = "Please see manual or README for further details" )

parser.add_argument('allele_files', metavar='ALLELE_FILES', nargs='*',
										help='Read TCR allele data from one or more IMGT-formatted fasta files')

parser.add_argument('--chr7-filename', metavar='FILE',
										help = "Filename of a FASTA formatted file with chromosome 7 reference data")
parser.add_argument('--chr14-filename', metavar='FILE',
										help = "Filename of a FASTA formatted file with chromosome 7 reference data")

parser.add_argument('--tcell-data', metavar='FILE',
										help = "Filename of a tab-separated file with T cell receptor segments and reference gene coordinates")

parser.add_argument("--output", metavar='BASENAME', default='stig.out',
										help='Basename for output files, e.g. \'--output=foo\' will write to \'foo.fastq\', \'foo.statistics.csv\', etc.  Default is \'stig.out\'')

parser.add_argument("--load-population", metavar='FILE', type=str,
										help='Load TCR population and repertoire data from FILE, rather than generating from scratch')

parser.add_argument('--repertoire-size', metavar='N', type=int, default=10,
										help='Size of the TCR repertoire (i.e. the number of unique TCRs that are generated).  Default is 10')
parser.add_argument('--repertoire-unique', action = 'store_true',
										help = "Force each TCR to be unique on the RNA level.  Default is to allow collisions")
parser.add_argument('--repertoire-chain-unique', action = 'store_true',
										help = "Force each TCR chain (e.g. alpha) to be unique on the RNA level.  Implies unique TCRs as per --repertoire-unique.  Default is to allow collisons")
parser.add_argument('--repertoire-cdr3-unique', action = 'store_true',
										help = "Force each CDR3 of each chain to be unique on the nucleotide level.  Implies unique TCRs as per --repertoire-unique and unique chains as per --repertoire-chain-unique.  Note this may cause performance issues as repertoire size increases.  Default is to allow collisons")
parser.add_argument('--population-size', metavar='N', type=int, default=100,
										help='The number of T-cells in the repertoire (e.g. if repertoire-sze=5 and population-size=15, then there are 3 clones of each unique TCR on average).  Default is 100')
parser.add_argument('--population-distribution', choices = ['gaussian', 'chisquare'], default='gaussian',
										help = 'Population distribution function.  This defines the function used to distribute the population among the repertoire.  Default is the (normalized) gaussian.  See --population-gaussian-parameters, --population-chisquare-parameters')

parserGroup1 = parser.add_mutually_exclusive_group()
parserGroup1.add_argument('--population-gaussian-parameters', metavar='N', type=float, default=3.0,
													help='Parameter for the normalized gaussian distribution.  The number of standard deviations to include in our population distribution.  Decimal value.  Default is 3')
parserGroup1.add_argument('--population-chisquare-parameters', metavar='k:cutoff', default='2:8',
													help='Parameters for the chi-square distribution.  Takes an argument formatted as \'k:cutoff\', where k - degrees of freedom.  Default is 3. cutoff - X-axis maximum.  Default is 8')

parser.add_argument('--read-type', choices = ['paired', 'single', 'amplicon'], default = 'single',
										help='Generate either single, paired-end, or amplicon reads.  Default is single')
parser.add_argument('--sequence-type', choices = ['dna', 'rna'], default = 'dna',
										help='Generate sequences from simulated DNA or RNA. Default is DNA')
parser.add_argument("--sequence-count", metavar="N", type=int, default=1000,
										help='Number of sequences (reads) to generate.  Default is 1000')
parser.add_argument("--read-length-mean", type=int, default=48,
										help='The average length of reads in nucleotides. Default is 48')
parser.add_argument("--read-length-sd", type=int, default=4,
										help='The SD of read length variation in nucleotides. Set to zero for fixed-length reads.  Default is 4')
parser.add_argument("--read-length-sd-cutoff", type=int, default=4, metavar='N',
										help='Read lengths are restricted to less than N standard deviations from the mean.  Default is 4')
parser.add_argument("--insert-length-mean", type=int, default=48,
										help='The average length of the insert for paired end reads.  Default is 48')
parser.add_argument("--insert-length-sd", type=int, default=4,
										help='The standard deviation of insert length variation in nucleotides. Set to zero for fixed-length inserts.  Default is 4')
parser.add_argument("--insert-length-sd-cutoff", type=int, default=4, metavar='N',
										help='Insert lengths are restricted to less than N standard deviations from the mean.  Default is 4')
parser.add_argument("--amplicon-probe", type=str, default='GATCTCTGCTTCTGATGGCTCAAACAC', metavar='STR',
										help="Anchoring/priming sequence for generating amplicon reads.  This should align with some RNA or DNA sequence, either sense or anti-sense.  Read 1 will have length given by --read-length-* options.  Read 2 will be complementary to read 1 and of an identical length.  The default value is a 27-mer that anchors on the reverse strand in EX1 of the beta chain C-region")

parserGroup2 = parser.add_mutually_exclusive_group()
parserGroup2.add_argument("--degrade-logistic", default=None, metavar="B:L:k:mid",
													help='Simulate non-optimal quality using the logistic (sigmoid) function.  Takes an argument formatted as \'B:L:k:mid\'.  B - Base error rate probability.  L - Maximum error rate. k - Steepness factor. mid - Midpoint, this is the base position where error rate is equal to 1/2 of L. Default is off.  This option is mutually exclusive to --degrade-phred, --degrade-fastq, and --degrade-fastq-random.  See: --degrade-variability')
parserGroup2.add_argument("--degrade-phred", metavar="PHRED_STRING", default=None,
													help='Simulate non-optimal quality using a Phred+33 (Illumina 1.8+) string to specify quality on a per-nucleotide basis.  If a generated read is longer than the given phred string, then the last character in the phred string is used.  Default is off.  This option is mutually exclusive to --degrade-logistic, --degrade-fastq and --degrade-fastq-random.  See: --degrade-variability')
parserGroup2.add_argument("--degrade-fastq", metavar="FILE[,FILE2]", default=None,
													help='Simulate non-optimal quality by degrading reads based on Phred+33 quality strings from the given fastq FILE, or files FILE1,FILE2. Two files required when generating paired or amplicon reads.  Output quality strings are assigned from FILE in a stepwise fashion')
parserGroup2.add_argument("--degrade-fastq-random", metavar='FILE[,FILE2]', default=None,
													help='Simulate non-optimal quality by degrading reads based on Phred+33 quality strings from the given fastq FILE, or files FILE1,FILE2.  Two files required when generating paired or amplicon reads.  Output quality strings are assigned from FILE randomly')

parser.add_argument("--degrade-variability", default=0, metavar='FLOAT', type=float,
										help='Applies a relative variability in the per-nucleotide error applied by the --degrade option.  If a given base were to have an error rate of 0.1 (10%%), then a degrade-variability of 0.5 (50%%) would result in an error rate in the range of 0.1 +/- 0.1 * 0.5.  Default is 0')

parser.add_argument("--display-degradation", action = 'store_true',
										help='Display the error rate per base pair for a given B:L:k:mid value and exit.  The number of positions displayed is adjustable through the --read-length-mean option.  This is mostly useful in adjusting these parameters to be passed to the --degrade option.  Note that no reads or repertoire will be generated when this option is given')

parser.add_argument("--receptor-ratio", metavar="RATIO", type=float, default=0.9,
										help='Ratio of alpha/beta vs gamma/delta sequences.  Default is 0.9 (9 alpha/beta per 1 gamma/delta TCR)')
parser.add_argument('--log-level', choices=['debug', 'info', 'warning', 'error', 'critical'], default='warning',
										help='Logging level.  Default is warning and above')

args = parser.parse_args()

# Process our logging level arguments
if( args.log_level == 'debug'):
  log.setLevel(logging.DEBUG)
elif( args.log_level =='info' ):
  log.setLevel(logging.INFO)
elif( args.log_level =='warning' ):
  log.setLevel(logging.WARNING)
elif( args.log_level =='error' ): 
  log.setLevel(logging.ERROR)
elif( args.log_level =='critical' ):
  log.setLevel(logging.CRITICAL)
else:
  log.error("Error: Unknown log level %s", args.log_level)


# Process degredation options: 'display-degradation', 'degrade-logistic', 'degrade-phred', 'degrade-fastq', and 'degrade-fastq-random'
degradeOptions = None
if ( args.degrade_logistic is not None or
		 args.degrade_phred is not None or
		 args.degrade_fastq is not None or
		 args.degrade_fastq_random is not None ):
		method, baseError, L, k, midpoint, phred, filename = [0] * 7 # Initialize to zero
		
		if args.degrade_logistic is not None:
				if re.match('^((?:\d+)|(?:\d*.\d+)):((?:\d+)|(?:\d*.\d+)):((?:\d+)|(?:\d*.\d+)):((?:\d+)|(?:\d*.\d+))$', args.degrade_logistic):
						log.info("Using logistic function for degradation")
						method = 'logistic'
						baseError, L, k, midpoint = args.degrade.split(':')
				else:
						log.critical("Invalid string for --degrade-logistic: \"%s\".  Valid example: 0.005:0.2:0.25:15", args.degrade_logistic)
						exit(-1)
		elif args.degrade_phred is not None:
				if re.match(r'^[!\"#\$%&\'\(\)\*\+,-./0123456789:;<=>?@ABCDEFGHIJ]+$', args.degrade_phred):
						log.info("Using Phred string for degradation")
						method = 'phred'
						matches = re.match('^(.+)$', args.degrade_phred)
						phred = matches.groups()[0]
				else:
						log.critical("Invalid argument for --degrade-phred: \"%s\".  Valid example: IIIIIIII444433", args.degrade_phred)
						exit(-1)
		elif args.degrade_fastq is not None:
				matches = re.search('^(.+),(.+)$', args.degrade_fastq)
				if matches is not None and args.read_type not in ('paired', 'amplicon'):
						log.critical("--args-degrade-fastq cannot take two filenames unless generating paired or amplicon reads")
						exit(-10)
				elif matches is None and args.read_type in ('paired', 'amplicon'):
						log.critical("--args-degrade-fastq must take two filenames when generating paired or amplicon reads")
						exit(-10)
				method = 'fastq'
				filename = args.degrade_fastq

		elif args.degrade_fastq_random is not None:
				matches = re.search('^(.+),(.+)$', args.degrade_fastq_random)
				if matches is not None and args.read_type not in ('paired', 'amplicon'):
						log.critical("--args-degrade-fastq cannot take two filenames unless generating paired or amplicon reads")
						exit(-10)
				elif matches is None and args.read_type in ('paired', 'amplicon'):
						log.critical("--args-degrade-fastq must take two filenames when generating paired or amplicon reads")
						exit(-10)

				method = 'fastq-random'
				filename = args.degrade_fastq_random				
		else:
				raise ValueError("Fallen through to an invalid choice for degradation")

		degradeOptions = {
				'method': method,
				'baseError': baseError,
				'L': L,
				'k': k,
				'midpoint': midpoint,
				'phred': phred,
				'filename': filename
				}

		
# Display degradation output, if --display-degradation given
if( args.display_degradation is True and
		degradeOptions is not None ):
		displayString = "A" * args.read_length_mean
		tempConfig = stigtools.tcrConfig()
		tempConfig.getDegradedFastq(displayString, method, 'ident',  variability=args.degrade_variability,
																phred=degradeOptions['phred'],
																baseError=degradeOptions['baseError'], L=degradeOptions['L'],
																k=degradeOptions['k'], midpoint=degradeOptions['midpoint'],
																display=True)
		exit(0)
elif args.display_degradation is True:
		raise ValueError("--display-degradation requires a degradation method.  See --degrade-logistic, --degrade-phred under help")


#  Make sure we have the necessary options given to generate synthetic reads
if( args.chr7_filename  is None or
		args.chr14_filename is None or
		args.tcell_data     is None or
		args.allele_files   is None ):
		log.critical("Required command-line options missing (chr7-filename, chr14-filename, tcell-data or allele files).  See --help")
		exit(-10)

		
# Throw some warnings based on unusual command-line options
if( args.read_length_mean > args.insert_length_mean ):
		log.warning("Insert length mean is less than read length mean, this may significantly increase read generation time.  Please ensure this is intentional.")

		
# Create our configuration object
my_configuration = stigtools.tcrConfig(log=log.getChild('tcrConfig'))
my_configuration.readTCRConfig(args.tcell_data)
my_configuration.readAlleles( args.allele_files )
my_configuration.setChromosomeFiles(chr7=args.chr7_filename, chr14=args.chr14_filename)


# Load our TCR repertoire from file, if requested
my_repertoire = None
if args.load_population is not None:
		print("Using previously saved T-cell population from %s, ignoring any --population... or --repertoire... options and using the settings from the saved file" % args.load_population)
		with open(args.load_population, 'rb') as fp:
				my_repertoire = cPickle.load(fp)
				my_repertoire.thaw(log=log.getChild('tcrRepertoire'), config=my_configuration)

else:
		log.info("Generating new repertoire")

		my_repertoire = stigtools.tcrRepertoire(my_configuration, args.repertoire_size,
																						AB_frequency=args.receptor_ratio,
																						uniqueTCR = args.repertoire_unique,
																						uniqueChain = args.repertoire_chain_unique,
																						uniqueCDR3 = args.repertoire_cdr3_unique,
																						log=log.getChild('tcrRepertoire'))

		# Populate the repertiore
		if args.population_distribution == 'gaussian':
				my_repertoire.populate(args.population_size, 'gaussian', g_cutoff = args.population_gaussian_parameters)
		elif args.population_distribution == 'chisquare':
				matches = re.match('^((?:\d+)|(?:\d*.\d+)):((?:\d+)|(?:\d*.\d+))$', args.population_chisquare_parameters)
				if( matches is not None and
						len(matches.groups()) == 2 ):
						k, cutoff = matches.groups()
						my_repertoire.populate(args.population_size, 'chisquare', cs_k=float(k), cs_cutoff=float(cutoff))
				else:
						raise ValueError("Invalid chi-square parameters: %s" % args.population_chisquare_parameters)
				

# Obtain our simulated reads, if requested
if args.sequence_count > 0:
		outputSequences = my_repertoire.simulateRead(args.sequence_count, args.sequence_type,
																								 read_length_mean      = args.read_length_mean,
																								 read_length_sd        = args.read_length_sd,
																								 read_length_sd_cutoff = args.read_length_sd_cutoff,
																								 insert_length_mean      = args.insert_length_mean,
																								 insert_length_sd        = args.insert_length_sd,
																								 insert_length_sd_cutoff = args.insert_length_sd_cutoff,
																								 amplicon_probe        = args.amplicon_probe,
																								 read_type = args.read_type )
		
		# Write the read sequences to output file(s)
		if args.read_type == 'single':
				outputFilename = args.output + '.fastq'
				with open(outputFilename, 'w') as fp:
						for readTuple in outputSequences:
								(read, comment) = readTuple
								qualStr = 'J'*len(read)
								fp.write("%s\n" % (comment))
								fp.write("%s\n" % (read))
								fp.write("+\n")
								fp.write("%s\n" % qualStr)
		elif args.read_type == 'paired' or args.read_type == 'amplicon':
				output1Filename = args.output + '_R1.fastq'
				output2Filename = args.output + '_R2.fastq'
				with open(output1Filename, 'w') as output1:
						with open(output2Filename, 'w') as output2:
								for readPairTuple in outputSequences:
										readPair, comment = readPairTuple
										read1, read2 = readPair
										qualStr1 = 'J'*len(read1)
										qualStr2 = 'J'*len(read2)
										
										output1.write("%s\n" % comment)
										output1.write("%s\n" % read1)
										output1.write("+\n")
										output1.write("%s\n" % qualStr1)
										
										output2.write("%s\n" % comment)
										output2.write("%s\n" % read2)
										output2.write("+\n")
										output2.write("%s\n" % qualStr2)
		else:
				raise ValueError("Unknown read_type encountered " + args.read_type)



		# Write degraded-quality reads, if requested by the user.  n.b. the cmd line options were parsed previously and placed in degradeOptions dict
		if degradeOptions is not None:
				method = degradeOptions['method']
				baseError = float(degradeOptions['baseError'])
				L = float(degradeOptions['L'])
				k = float(degradeOptions['k'])
				midpoint = float(degradeOptions['midpoint'])
				phred = degradeOptions['phred']
				filename = degradeOptions['filename']

				# Phred strings used for degradation are read from an array
				phred1 = [ phred ]
				phred2 = [ phred ]
				
				# If the user requests we degrade based on FASTQ quality strings, read them into arrays
				if method == 'fastq' or method == 'fastq-random':
						log.debug("Using FASTQ-based degradation")
						method = 'phred' # This is implemented as a special case of Phred degredation
						phred1 = []
						phred2 = []
						
						matches = re.search('^(.+),(.+)$', filename)
						if matches is not None:
								filename1 = matches.group(1)
								filename2 = matches.group(2)
								log.debug("Fastq-degrade filenames are %s and %s", filename1, filename2)
								phred1 = my_configuration.getFastqQualities(filename1)
								phred2 = my_configuration.getFastqQualities(filename2)
								if len(phred1) <= 0:
										log.critical("Invalid number of fastq quality strings %d in file %s", phred1.len(), filename)
										exit(-10)
								if len(phred2) <= 0:
										log.critical("Invalid number of fastq quality strings %d in file %s", phred2.len(), filename)								
										exit(-10)										
						else:
								log.debug("Fastq-degrade filename is %s", filename)
								phred1 = my_configuration.getFastqQualities(filename)
								if len(phred1) <= 0:
										log.critical("Invalid number of fastq quality strings %d in file %s", phred1.len(), filename)
										exit(-10)
						if method == 'fastq-random':
								shuffle(phred1)
								shuffle(phred2)
										
				if args.read_type == 'single':
						outputFilename = args.output + '.degraded.fastq'
						with open(outputFilename, 'w') as fp:
								i = 0
								for readTuple in outputSequences:
										read, comment = readTuple
										ident = comment.replace('@STIG', '@STIG_DEGRADED')
										fp.write(my_configuration.getDegradedFastq(read, method, ident, variability=args.degrade_variability, phred=phred1[i % len(phred1)], baseError=baseError, L=L, k=k, midpoint=midpoint))
										i += 1
				elif args.read_type == 'paired' or args.read_type == 'amplicon':
						output1Filename = args.output + '_R1.degraded.fastq'
						output2Filename = args.output + '_R2.degraded.fastq'
						with open(output1Filename, 'w') as output1:
								with open(output2Filename, 'w') as output2:
										i = 0
										for readPairTuple in outputSequences:
												readPair, comment = readPairTuple
												read1, read2 = readPair
												ident = comment.replace('@STIG', '@STIG_DEGRADED')
												output1.write(my_configuration.getDegradedFastq(read1, method, ident, variability=args.degrade_variability, phred=phred1[i % len(phred2)], baseError=baseError, L=L, k=k, midpoint=midpoint))
												output2.write(my_configuration.getDegradedFastq(read2, method, ident, variability=args.degrade_variability, phred=phred2[i % len(phred1)], baseError=baseError, L=L, k=k, midpoint=midpoint))
												i += 1
				else:
						raise ValueError("Unknown read_type encountered" + args.read_type)


if args.load_population is None:
		# Write statistics to an output file
		statsFilename = args.output + '.statistics.csv'
		with open(statsFilename, 'w') as fp:
				for i in my_repertoire.getStatistics(addHeader = True):
						fp.write(",".join(str(e) for e in i) + "\n")

		# Write our repertoire object to a file
		populationFilename = args.output + '.population.bin'
		with open(populationFilename, 'wb') as fp:
				cPickle.dump(my_repertoire.freeze(), fp)


log.info("All actions complete")
exit(0)


